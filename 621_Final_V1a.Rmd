---
title: "621-Final Project"
author: "Brian Kreis"
date: "May 1, 2018"
output:
  html_document:
    df_print: paged
---

---
title: 'Group#2 Final'
author: "Group 2"
date: "4/30/2018"
output:
  html_document: default
  pdf_document:
    latex_engine: lualatex
  word_document: default
---

#Introduction
Our project team has obtained a data set containing 30,000 observations with each observation representing a credit card customer. Variables included in the data set provide information on that customer's payment history, outstanding balances as well as demographic information. It is our task to develop a binary logistic regression model to predict the probability that a customer will be in default of their next scheduled payment. The data set contains our default payment response variable, which is binary (0,1), an ID field, and 23 predictor variables. We will break the data set into a training and test set for our evaluation. 

The objective is to build multiple binary logistic regression models on the training data to predict the probability that a person will be in default of payment. We will then run analysis to determine which model performed best. 

This model may be useful for financial institutions who provide revolving credit facilities to determine which customers may need intervention, including where reduction in the size of the outstanding credit facility would be prudent. 


##Team Members
-Valerie Briot
-Michael D'acampora
-Keith Folsom
-Brian Kreis
-Sharon Morris



```{r libraries, echo=FALSE, message=FALSE, warning=FALSE}
library(psych)
library(GGally)
library(ggplot2)
library(ggthemes)
library(reshape2)
# library(VIM)
# library(mice)
# library(stringr)
# library(dplyr)
# library(car)
# library(usdm)
# library(tidyverse)
# library(stringr)
library(DataExplorer)
library(knitr)
# library(corrplot)
# library(MASS)
# library(tinytex)
# library(ggfortify)
library(caret)
library(pscl)
library(MKmisc)
library(Metrics)
library(pROC)
library(rpart)

# library(gvlma)  ## only used for confirming model assumptions

options(scipen=999)

```
#Dataset
For reproducibility of the results, the data was loaded to and accessed from a Github repository. 

```{r Read data, echo=FALSE, message=FALSE, warning=FALSE}
cc_data <- read.csv("https://raw.githubusercontent.com/621-Group2/Final-Project/master/UCI_Credit_Card.csv", header=TRUE, sep=",")

#Remove the id from the dataset
cc_data$ID <- NULL

#Simplify name of response
colnames(cc_data)[24] <- "DEFAULT" 







# get_outliers function
get_outliers <-  function(x, n = 10) {
  
  bp <- boxplot.stats(x)
  
  obs_hi <- unique(x[which(x > bp$stats[5])])

  if (length(obs_hi) < n) { n <- length(obs_hi) }

  hi <- sort(obs_hi, decreasing = T)[1:n]
  
  obs_low <- unique(x[which(x < bp$stats[1])])

  if (length(obs_low) < n) { n <- length(obs_low) }

  low <- sort(obs_low, decreasing = T)[1:n]

  return (list(Hi=hi, Low=low))
  
}  

#Keith's function
all_model_metrics <- data.frame()
all_roc_curves <- list()
all_predictions <- list()

calc_metrics <- function(model_name, model, test, train, show=FALSE) {
  
  
  pred_model <- predict(model, test, type = 'response')
  y_pred_model <- as.factor(ifelse(pred_model > 0.5, 1, 0))
  
  # psedo R2 value (McFaden):
  McFadenR2_value <- pR2(model1)[[4]]
  
  # Hosmer L    Test:
  HosmerL_value <- HLgof.test(fit = fitted(model), obs = train$target)
  HL_Chi_value <- unname(HosmerL_value$C[1]$statistic[1])
  HL_p_value <- unname(HosmerL_value$C[3]$p.value[1])
  # Handle very low p-value
  HL_p_value_limit <- 2.2*(10^(-16))
  HL_p_value_flag <- ' '
  if (HL_p_value <= HL_p_value_limit) {
    HL_p_value_flag <- '*'
    HL_p_value <- HL_p_value_limit
  }
  
  # Confusion Matrix
  cm <- confusionMatrix(test$target, y_pred_model, positive = "1", mode="everything" ) 
  
  kappa_value <- cm$overall[[2]]
  youden_value <- cm$byClass[[1]] - (1 - cm$byClass[[2]])
  F1Score_value <- cm$byClass[[7]]
  FP_value <- (cm$table[2,1]/nrow(test))*100
  
  #AUC
  AUC_value <- auc(test$target, pred_model)
  
  cm_df <- data.frame(Model=model_name, 
                      AIC=round(AIC(model), 3), 
                      BIC=round(BIC(model), 3), 
                      McFadenR2 = round(McFadenR2_value, 3), 
                      HL_Chi = round(HL_Chi_value, 3),
                      HL_p = HL_p_value, 
                      '*' = HL_p_value_flag, 
                      Kappa = round(kappa_value, 3), 
                      Youden = round(youden_value, 3), 
                      F1Score = round(F1Score_value, 3),
                      FPPrct = round(FP_value, 2), 
                      AUC = round(AUC_value[[1]], 3))
  
  #cbind(t(cm$overall),t(cm$byClass)))
  
  # ROC Curves 
  roc_model <- roc(target ~ pred_model, data = test)
  
  # Result
  result <- list(cm_df, roc_model, pred_model)
  if (show) { 
    
    # calculate AIC/BIC
    print(paste("AIC= ", round(AIC(model), 3)))
    print(paste("BIC= ", round(BIC(model), 3)))
    print("")
    
    print(cm)
  }
  
  return (result)
  
}

```


#Data Exploration and Statistic Measures
The purpose of the data exploration and statistic measures phase is to understand the data to determine how to process the dataset for modelling. 

##Missing and Zero Values
The data does not contain missing values and as such no imputation will be necessary.



```{r miss_plot, echo=FALSE, message=FALSE, warning=FALSE}

plot_missing(cc_data, title="Credit Card Data - Missing Values (%)")

```

##Variable to Variable Analysis
```{r data exploration, echo=FALSE, message=FALSE, warning=FALSE}

Variable <- colnames(cc_data)

Definition <- c("Amount of given credit in NT dollars", "Gender (1=male, 2=female)", "(1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)", "Marital status (1=married, 2=single, 3=others)", "Age in Years", "Repayment status in September, 2005", "Repayment status in August, 2005", "Repayment status in July, 2005", "Repayment status in June, 2005", "Repayment status in May, 2005", "Repayment status in April, 2005", "Amount of bill statement in September, 2005", "Amount of bill statement in August, 2005", "Amount of bill statement in July, 2005", "Amount of bill statement in June, 2005", "Amount of bill statement in May, 2005", "Amount of bill statement in April, 2005", " Amount of previous payment in September, 2005", " Amount of previous payment in August, 2005", " Amount of previous payment in July, 2005", " Amount of previous payment in June, 2005", " Amount of previous payment in May, 2005", " Amount of previous payment in April, 2005", "Default payment (1=yes, 0=no)")

card_sum <- cbind.data.frame (Variable, Definition)

card_sum$Type <- "Predictor"
card_sum[24,3] <- "Response"





knitr::kable(card_sum)
```

##Descriptive Statistics

Descriptive statistics was performed for all predictor and response variables to explore the data. 

```{r descriptive statistics, echo=FALSE, message=FALSE, warning=FALSE}

#Use Describe Package to calculate Descriptive Statistic
(CC_des <- describe(cc_data, na.rm=TRUE, interp=FALSE, skew=TRUE, ranges=TRUE, trim=.1, type=3, check=TRUE, fast=FALSE, quant=c(.1,.25,.75,.90), IQR=TRUE))


```





##Analysis of Variables
```{r echo=FALSE, message=FALSE, warning=FALSE}
#Temporary dataset turned to factors for visualization
cc_dataT <- cc_data
vars3 <- c("SEX", "MARRIAGE", "EDUCATION", "DEFAULT")

cc_dataT[vars3] <- lapply(cc_dataT[vars3], factor)

#Check ordering 
table(cc_dataT$PAY_0)
```

##LIMIT_BAL
The majority of customers have lower credit limits, as such the distribution is right skewed
```{r bal, echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=(c(1,2)))
ggplot(cc_dataT, aes(x = LIMIT_BAL, fill = DEFAULT)) +
  geom_histogram() +
  labs(x = 'Credit Limit') +
  theme_gdocs()

ggplot(cc_dataT, aes(x=LIMIT_BAL, y=LIMIT_BAL)) + 
  geom_boxplot()+
  theme_pander()
```


##SEX
The majority of customers are female
```{r sex, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(cc_dataT, aes(x = SEX, fill = DEFAULT)) +
  geom_bar() +
  labs(x = 'SEX') +
  theme_pander()

```




##EDUCATION
The majority of customers went to university, there are very few in the other/unknown categories as well as an unknown 0 value and we will consider combining.
```{r edu, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(cc_dataT, aes(x = EDUCATION, fill = DEFAULT)) +
  geom_bar() +
  labs(x = 'EDUCATION') +
  theme_pander()

```


##MARRIAGE
The majority of customers are single and the proportion of default payments appears to be higher for married individual. It appears that there are 0 values here which were not planned. It may be prudent to instead code this as a binary married variable.
```{r marriage, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(cc_dataT, aes(x = MARRIAGE, fill = DEFAULT)) +
  geom_bar() +
  labs(x = 'MARRIAGE') +
  theme_pander()
```

##AGE
The distribution is right skewed. We can see that extremely young customers seem to have a higher proportion of defaults.
```{r age, echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=(c(1,2)))
ggplot(cc_dataT, aes(x = AGE, fill = DEFAULT)) +
  geom_histogram() +
  labs(x = 'AGE') +
  theme_pander()

ggplot(cc_dataT, aes(x=AGE, y=AGE)) + 
  geom_boxplot()+
  theme_pander()
```

##Repayment Status
The vast majority of clients are on time or ahead of payments. The number of extremely late payments in the latter months are more infrequent. We can presume that this list only contains customers who's accounts have not yet been charged off, for which we would expect no future payments. Customers with extrmely late repayment statuses 6 months ago have lively already been charged off. 

One issue appears to exist. Moving from PAY_4 (July) to PAY_3 (JUNE) the number of late payments increases. THis should be a gradual movement of clients from one period to the next, so the sudden appearance of frequencies at 6 months late and over does not seem logical. 

```{r repay, echo=FALSE, message=FALSE, warning=FALSE}

par(mfrow=(c(1,1)))
ggplot(stack(cc_dataT[,6:11]), aes(values, fill=ind))+
  facet_wrap(~ind, scales = "free") + 
  geom_bar() +
  theme_pander()+
  theme(legend.position="none")


```

##Bill Amount
We appear to have some negaive values for bill amount. This likely represents overpayment by the customer and is not problematic. The distributions are similar.

```{r bill, echo=FALSE, message=FALSE, warning=FALSE}

par(mfrow=(c(1,2)))
ggplot(stack(cc_dataT[,12:17]), aes(values, fill=ind))+
  facet_wrap(~ind, scales = "free") + 
  geom_histogram() +
  theme_pander() +
  theme(legend.position="none")

ggplot(stack(cc_dataT[,12:17]), aes(x = ind, y = values, fill=ind))+
  facet_wrap(~ind, scales = "free") + 
  geom_boxplot() +
  theme_pander() +
  theme(legend.position="none")
```

##Pay Amount
The majority of payments are small with some rather large outliers. 

```{r pay, echo=FALSE, message=FALSE, warning=FALSE}

par(mfrow=(c(1,2)))
ggplot(stack(cc_dataT[,18:23]), aes(values, fill=ind))+
  facet_wrap(~ind, scales = "free") + 
  geom_histogram() +
  theme_pander() +
  theme(legend.position="none")

ggplot(stack(cc_dataT[,18:23]), aes(x = ind, y = values, fill=ind))+
  facet_wrap(~ind, scales = "free") + 
  geom_boxplot() +
  theme_pander() +
  theme(legend.position="none")
```


##DEFAULT
As we would expect the majority of customers are not in defualt of their next payment. 
```{r default, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(cc_dataT, aes(x = DEFAULT)) +
  geom_bar(fill="blue") +
  labs(x = 'DEFAULT') +
  theme_pander()

```


##Data Manipulation
As discussed previously, we will combine values 4, 5 and 6 in education to create an all encompassing other category. We will also change the unknown value of 0 in MARRIAGE to 3(other) 


##Recode Predictors

```{r}
cc_data$MARRIED <- ifelse(cc_data$MARRIAGE==1, 1, 0)

cc_data$MALE <- ifelse(cc_data$SEX==1, 1, 0)

cc_data$EDU_HIGH_SCHOOL_Other <- ifelse(cc_data$EDUCATION %in% c(3,4,5,6,0), 1, 0) 
cc_data$EDU_COLLEGE <- ifelse(cc_data$EDUCATION== 2, 1, 0)
cc_data$EDU_ADV_DEGREE <- ifelse(cc_data$EDUCATION == 1, 1, 0) 

cc_dataR <- dplyr::select(cc_data, -EDUCATION, -MARRIAGE, -SEX)
```


##Change values to factors

```{r}

#Check for data type
sapply(cc_dataR,class)

#convert categorical to factor variables so that R can create dummy variables
#ordered
# vars1 <- c("EDUCATION", "PAY_0", "PAY_2", "PAY_3", "PAY_4", "PAY_5", "PAY_6")
# cc_data[vars1] <- lapply(cc_data[vars1], ordered)

#unordered
vars2 <- c("MALE", "MARRIED", "EDU_HIGH_SCHOOL_Other","EDU_ADV_DEGREE", "EDU_COLLEGE","DEFAULT")
cc_dataR[vars2] <- lapply(cc_dataR[vars2], factor)



```

##Correlation Analysis
As shown below there is high collinearity among variables where we would expect it to occur. For instance in Bill Amount, for which we have six variables all corresponding to different months, we would expect a relation between the amount someone owes one month and the amount that they owe the next. This is also true of the Payment Amount variable, for which we also have 6 sequential months of data for.

Also as we would expect, the DEFAULT variable is most strongly correlated with the payment status. If a person were to default in one payment period, intuitively we would think that may have a relationship with other periods. 

The tables below represent correlation between response and predictor variables.

```{r correlation, echo=FALSE, message=FALSE, warning=FALSE, fig.height=8, fig.width=10}
ggcorr(cc_dataR, method = "pairwise", label=TRUE, nbreaks=6)


```



```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=8, fig.width=10}
#rename response and split into test and training set 

colnames(cc_dataR)[21] <- "target"

smp <- floor(0.70 * nrow(cc_dataR))
set.seed(4784)
train_index <- sample(seq_len(nrow(cc_dataR)), size = smp, replace = FALSE)

train_all <- cc_dataR[train_index, ]
test_all <- cc_dataR[-train_index, ]



```

##Model 1

This model performed quite poorly as we would expect with this many correlated variables.
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=8, fig.width=10}
#all base variables
model1 <- glm(target ~ .,
             data=train_all,
             family = binomial(link="logit"))
model1step <- step(model1, direction="both", trace=0)

summary(model1step)


m2<- calc_metrics("Model1 - StepWise Non Transformed", model1step, test_all, train_all, show=F)
all_model_metrics <- rbind(all_model_metrics, m2[[1]])

all_roc_curves[[2]] <- m2[[2]]

all_predictions[[2]] <- m2[[3]]
```

##Model 2

#PCA component analysis

As mentioned earlier we have quite a bit of collinearity among predictors, as demonstrated by the screeplot below; the variability accounted for by each component drops sharpely within the first few components. 

```{r}
trainX <- subset(train_all, select = -target)
trainY <- subset(train_all, select = target)

testX <- subset(test_all, select = -target)
testY <- subset(test_all, select = target)

pca_val <- princomp(na.omit(trainX))

screeplot(pca_val, type = "lines")
```







